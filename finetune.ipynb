{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d542b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e0c9fc-da6c-4939-8a9b-06bf3eb96791",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 1.13.1\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from argparse import Namespace\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from heterogt.utils.tokenizer import EHRTokenizer\n",
    "from heterogt.utils.dataset import FineTuneEHRDataset, batcher, expand_level3\n",
    "from heterogt.utils.train import PHENO_ORDER, train_with_early_stopping\n",
    "from heterogt.utils.seed import set_random_seed\n",
    "from heterogt.model.model import HeteroGTFineTune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc103a4-3cfe-4160-93c9-59f02bf53f02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random seed set to 123\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d002f3a7-c093-4d0e-9ddd-0913e1b71534",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00f61efc-5817-4764-9c39-806e70eed7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Namespace(\n",
    "    dataset = \"MIMIC-IV\", # MIMIC-III or MIMIC-IV\n",
    "    tasks = [\"death\", \"readmission\", \"stay\", \"next_diag_12m\"],\n",
    "    task_index = 1,  # index of the task to train, use it to index the above tasks, e.g., 1 == \"readmission\"\n",
    "    token_type = [\"diag\", \"med\", \"lab\", \"pro\"],\n",
    "    special_tokens = [\"[PAD]\", \"[CLS]\"],\n",
    "    # only for tf layer\n",
    "    attn_mask_dicts = [{1:[6,7], 2:[6,7], 3:[6,7], 4:[6,7], 5:[6,7], 6:[1,2,3,4,5,6,7], 7:[1,2,3,4,5,6,7]}, \n",
    "                       {1:[6,7], 2:[6,7], 3:[6,7], 4:[6,7], 5:[6,7], 6:[1,2,3,4,5,6,7], 7:[1,2,3,4,5,6,7]}], \n",
    "    d_model = 64,\n",
    "    num_heads = 4,\n",
    "    batch_size = 32,\n",
    "    lr = 1e-3,\n",
    "    epochs = 500,\n",
    "    early_stop_patience = 5,\n",
    "    group_code_thre = 5,  # if there are group_code_thre diag codes belongs to the same group ICD code, then the group code is generated\n",
    "    use_pretrained_model = True,\n",
    "    pretrain_mask_rate = 0.7,\n",
    "    pretrain_cls_ontology_weight = 5e-2,\n",
    "    pretrain_visit_ontology_weight = 5e-2,\n",
    "    pretrain_adm_type_weight = 0,\n",
    "    dec_loss_lambda = 1e-2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8350e183-675c-4d4e-9d5a-c7c91bcfaf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current task: readmission\n"
     ]
    }
   ],
   "source": [
    "full_data_path = f\"./data_process/{config.dataset}-processed/mimic.pkl\"  # for tokenizer\n",
    "curr_task = config.tasks[config.task_index]\n",
    "print(\"Current task:\", curr_task)\n",
    "if curr_task == \"next_diag_6m\":\n",
    "    finetune_data_path = f\"./data_process/{config.dataset}-processed/mimic_nextdiag_6m.pkl\"\n",
    "elif curr_task == \"next_diag_12m\":\n",
    "    finetune_data_path = f\"./data_process/{config.dataset}-processed/mimic_nextdiag_12m.pkl\"\n",
    "else:\n",
    "    finetune_data_path = f\"./data_process/{config.dataset}-processed/mimic_downstream.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cbf0169-7a45-42a5-ac14-377262c79845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max admissions per patient: 8\n"
     ]
    }
   ],
   "source": [
    "ehr_full_data = pickle.load(open(full_data_path, 'rb'))\n",
    "group_code_sentences = [expand_level3()[1]]\n",
    "diag_sentences = ehr_full_data[\"ICD9_CODE\"].values.tolist()\n",
    "med_sentences = ehr_full_data[\"NDC\"].values.tolist()\n",
    "lab_sentences = ehr_full_data[\"LAB_TEST\"].values.tolist()\n",
    "pro_sentences = ehr_full_data[\"PRO_CODE\"].values.tolist()\n",
    "age_sentences = [[str(c)] for c in set(ehr_full_data[\"AGE\"].values.tolist())] # important of [[]]\n",
    "adm_type_sentences = ehr_full_data[\"ADMISSION_TYPE\"].values.tolist()\n",
    "max_admissions = ehr_full_data.groupby(\"SUBJECT_ID\")[\"HADM_ID\"].nunique().max()\n",
    "config.max_num_adms = max_admissions\n",
    "print(f\"Max admissions per patient: {config.max_num_adms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30b03d91-beb3-4760-b0ba-30cb3653afde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age vocabulary size: 20\n",
      "Group code vocabulary size: 19\n"
     ]
    }
   ],
   "source": [
    "tokenizer = EHRTokenizer(age_sentences, group_code_sentences, diag_sentences, med_sentences, lab_sentences, \n",
    "                         pro_sentences, special_tokens=config.special_tokens, adm_types_sentences=adm_type_sentences)\n",
    "config.label_vocab_size = len(PHENO_ORDER)  # a set of predifined diseases\n",
    "config.global_vocab_size = len(tokenizer.vocab.id2word)\n",
    "config.age_vocab_size = tokenizer.token_number(\"age\")\n",
    "config.group_code_vocab_size = tokenizer.token_number(\"group\")\n",
    "print(f\"Age vocabulary size: {config.age_vocab_size}\")\n",
    "print(f\"Group code vocabulary size: {config.group_code_vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7aeadab-16ee-4ec5-b0b3-34c0c9bf32ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of DEATH in test dataset: 9.077523846104603 %\n",
      "Percentage of READMISSION in test dataset: 70.78932206644902 %\n",
      "Percentage of STAY>7 days in test dataset: 33.36534152743103 %\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data = pickle.load(open(finetune_data_path, 'rb'))\n",
    "# example label percentage\n",
    "print(\"Percentage of DEATH in test dataset:\",\n",
    "      (test_data[\"DEATH\"] == True).mean() * 100, \"%\")\n",
    "\n",
    "print(\"Percentage of READMISSION in test dataset:\",\n",
    "      (test_data[\"READMISSION\"] == 1).mean() * 100, \"%\")\n",
    "\n",
    "print(\"Percentage of STAY>7 days in test dataset:\",\n",
    "      (test_data[\"STAY_DAYS\"] > 7).mean() * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28835e8c-021b-46d4-8183-bf2c41605a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FineTuneEHRDataset(train_data, tokenizer, token_type=config.token_type, task=curr_task, \n",
    "                                   max_num_adms=config.max_num_adms, group_code_thre=config.group_code_thre)\n",
    "val_dataset = FineTuneEHRDataset(val_data, tokenizer, token_type=config.token_type, task=curr_task, \n",
    "                                 max_num_adms=config.max_num_adms, group_code_thre=config.group_code_thre)\n",
    "test_dataset = FineTuneEHRDataset(test_data, tokenizer, token_type=config.token_type, task=curr_task, \n",
    "                                   max_num_adms=config.max_num_adms, group_code_thre=config.group_code_thre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef02f6c0-88b5-49a4-86ed-1b5b971f6e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean group token numer per patient 1.0251935441543105\n"
     ]
    }
   ],
   "source": [
    "num_group_code = []\n",
    "for i in range(len(train_dataset)):\n",
    "    input_ids, token_types, adm_index, age_ids, diag_group_codes, labels = train_dataset[i]\n",
    "    count = (token_types[0] == 6).sum().item()\n",
    "    num_group_code.append(count)\n",
    "print(\"Mean group token numer per patient\", np.mean(num_group_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "110d1b03-48aa-4d22-84b6-6937376a5062",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    collate_fn=batcher(tokenizer, n_token_type=len(config.token_type), is_pretrain = False),\n",
    "    shuffle=True,\n",
    "    batch_size=config.batch_size,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    collate_fn=batcher(tokenizer, n_token_type=len(config.token_type), is_pretrain = False),\n",
    "    shuffle=False,\n",
    "    batch_size=config.batch_size,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    collate_fn=batcher(tokenizer, n_token_type=len(config.token_type), is_pretrain = False),\n",
    "    shuffle=False,\n",
    "    batch_size=config.batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e18f4dde-f646-41c3-b26a-0d18068088c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pass!\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    pass  # just to check if the dataloader works\n",
    "for batch in val_dataloader:\n",
    "    pass  # just to check if the dataloader works\n",
    "for batch in test_dataloader:\n",
    "    pass  # just to check if the dataloader works\n",
    "print(\"All pass!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "247a64c4-9ea9-4bbd-a5e3-c0f4757f6507",
   "metadata": {},
   "outputs": [],
   "source": [
    "if curr_task in [\"death\", \"stay\", \"readmission\"]:\n",
    "    eval_metric = \"f1\"\n",
    "    task_type = \"binary\"\n",
    "    loss_fn = F.binary_cross_entropy_with_logits\n",
    "else:\n",
    "    eval_metric = \"f1\"\n",
    "    task_type = \"l2r\"\n",
    "    loss_fn = lambda x, y: F.binary_cross_entropy_with_logits(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaf4c431-1541-4324-b289-55a8cb137f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([32, 242])\n",
      "Token Types shape: torch.Size([32, 242])\n",
      "Admission Index shape: torch.Size([32, 242])\n",
      "Age IDs shape: torch.Size([32, 6])\n",
      "Diag Code Group Dict number: 32\n",
      "Labels shape: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "input_ids, token_types, adm_index, age_ids, diag_code_group_dicts, labels = next(iter(train_dataloader))\n",
    "print(\"Input IDs shape:\", input_ids.shape)\n",
    "print(\"Token Types shape:\", token_types.shape)\n",
    "print(\"Admission Index shape:\", adm_index.shape)\n",
    "print(\"Age IDs shape:\", age_ids.shape)\n",
    "print(\"Diag Code Group Dict number:\", len(diag_code_group_dicts))\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78df02ae-70d8-484a-8495-1e32e99146dd",
   "metadata": {},
   "source": [
    "# Model Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4561944-6ad8-4582-8877-d5db3be1580f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference: 100%|██████████| 489/489 [00:20<00:00, 23.37it/s]\n",
      "Running inference: 100%|██████████| 489/489 [00:21<00:00, 23.10it/s]\n",
      "Running inference: 100%|██████████| 489/489 [00:20<00:00, 23.60it/s]\n",
      "Running inference: 100%|██████████| 489/489 [00:20<00:00, 23.59it/s]\n",
      "Running inference: 100%|██████████| 489/489 [00:21<00:00, 23.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "if config.use_pretrained_model:\n",
    "    pretrain_exp_name = (\n",
    "    f\"{config.dataset}-{config.pretrain_mask_rate}-{config.d_model}-{config.pretrain_cls_ontology_weight}-{config.pretrain_visit_ontology_weight}-{config.pretrain_adm_type_weight}\"\n",
    ")\n",
    "    print(pretrain_exp_name)\n",
    "    save_path = \"./parameters/pretrained_models/\" + pretrain_exp_name\n",
    "    state_dict = torch.load(f\"{save_path}/pretrained_model.pt\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de272ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_metrics = []\n",
    "for i in range(5):\n",
    "    print(f\"================================{i+1}==================================\")\n",
    "    model = HeteroGTFineTune(tokenizer=tokenizer, token_types=config.token_type, d_model=config.d_model, num_heads=config.num_heads, \n",
    "                             layer_types=['gnn', 'tf', 'gnn', 'tf'], max_num_adms=config.max_num_adms, \n",
    "                             device=device, task=curr_task, label_vocab_size=config.label_vocab_size, attn_mask_dicts=config.attn_mask_dicts,\n",
    "                             use_cls_cat=True).to(device)\n",
    "    if config.use_pretrained_model:\n",
    "        model.load_weight(state_dict)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr)\n",
    "    best_test_metric, best_test_long_seq_metric = train_with_early_stopping(model, train_dataloader, val_dataloader, test_dataloader,\n",
    "                                                                            optimizer, loss_fn, device, config.early_stop_patience, task_type, config.epochs, \n",
    "                                                                            dec_loss_lambda=config.dec_loss_lambda, \n",
    "                                                                            val_long_seq_idx=None, test_long_seq_idx=None, \n",
    "                                                                            eval_metric=eval_metric, return_model=False)\n",
    "    final_metrics.append(best_test_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a64fccf8-a0ed-47e8-adb9-94e7946541e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def avg_performance_formatted(performances):\n",
    "    final_avg = {m: np.mean([p[m] for p in performances]) for m in performances[0].keys()}\n",
    "    final_std = {m: np.std([p[m] for p in performances], ddof=0) for m in performances[0].keys()}\n",
    "\n",
    "    print(\"Final Metrics:\")\n",
    "    for m in performances[0].keys():\n",
    "        mean_val = final_avg[m]\n",
    "        std_val = final_std[m]\n",
    "        print(f\"{m}: {mean_val:.2f} ± {std_val:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92d3b5d1-7ce0-4ef3-92dd-0b2e30449d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phenotyping_prediciton_avg_performance(dfs, col_name=\"prauc\"):\n",
    "    all_values = pd.concat(dfs, axis=0)\n",
    "    grouped = all_values.groupby(all_values.index)[col_name].agg([\"mean\", \"std\"])\n",
    "    for disease, row in grouped.iterrows():\n",
    "        mean_val = row[\"mean\"]\n",
    "        std_val = row[\"std\"]\n",
    "        print(f\"{disease}: {mean_val:.2f} ± {std_val:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c82f49e-2b03-4fcb-8624-f39b714926cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Metrics:\n",
      "precision: 75.00 ± 0.76\n",
      "recall: 95.77 ± 1.67\n",
      "f1: 84.10 ± 0.19\n",
      "auc: 71.27 ± 0.19\n",
      "prauc: 84.34 ± 0.18\n"
     ]
    }
   ],
   "source": [
    "if task_type == \"binary\":\n",
    "    avg_performance_formatted(final_metrics)\n",
    "else:\n",
    "    final_metrics_global = [metrics[\"global\"] for metrics in final_metrics]\n",
    "    final_metrics_per_class = [metrics[\"per_class\"] for metrics in final_metrics]\n",
    "    avg_performance_formatted(final_metrics_global)\n",
    "    print(\"\\nPer-class performance, all patients:\")\n",
    "    phenotyping_prediciton_avg_performance(final_metrics_per_class, col_name=\"prauc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heart-cuda",
   "language": "python",
   "name": "heart-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
